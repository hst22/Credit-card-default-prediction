---
title: "Credit card default predictions"
output: html_notebook
---

#### Libraries
```{r Libraries, include=FALSE}
library(dplyr)
library(caTools)
library(DataExplorer)
library(DMwR)
library(rpart)
library(rpart.plot)
library(boot)
library(randomForest)
library(ggplot2)
library(ROCR)
```


```{r include=FALSE}
setwd("D:\\University\\Pet projects\\credit-card-approval-prediction")
```

#### Importing the "application_records" dataset
```{r Data Import 1}
credit.card = read.csv("application_record.csv") 

dim(credit.card)

colnames(credit.card)
```
Explain what the data set contains
* The "application_record" data contains application information which can be used for predicting defaulters
* The data contains 438,557 observations and 18 variables

#### Summary and Structure of the application data
```{r Summary 1}
str(credit.card)
summary(credit.card)
```
Observations
* The data has variables of different data types, including integers, factors, and numericals
* Variables such as FLAG_MOBIL, FLAG_WORK_PHONE, FLAG_PHONE, and FLAG_EMAIL are binary but are captured as integers here
* ID variable is customer identifier here
* DAYS_BIRTH and DAYS_EMPLOYED have negative values which signifies measurement of days back from the date of observation. For e.g. -1 will indicate 1 day before the day of observation

#### Importing the "credit_record" data set

The "credit_record" data contains users' behaviour on credit card. The behaviour is assessed in terms of the credit card balance and the status of the card in a particular month
```{r Data import 2}
credit.record = read.csv("credit_record.csv")
dim(credit.record)
names(credit.record)
```
* The dataset has 1,048,575 observations and 3 variables 

#### Summary and Structure of the data
```{r Summary 2}
str(credit.record)
summary(credit.record)
```

Note:
* MONTHS_BALANCE variable: Month of the extracted data is the starting point, backwards, 0 is the current month, -1 is the previous month, and so on
* STATUS: 
0: 1-29 days past due 
1: 30-59 days past due 
2: 60-89 days overdue 
3: 90-119 days overdue 
4: 120-149 days overdue 
5: Overdue or bad debts, write-offs for more than 150 days 
C: paid off that month 
X: No loan for the month

#### Variable type modification for analysis

As per the aforementioned observations variable modifications were done on the application record dataset
```{r Variable type correction}
credit.card$FLAG_MOBIL  = as.factor(credit.card$FLAG_MOBIL)
credit.card$FLAG_WORK_PHONE  = as.factor(credit.card$FLAG_WORK_PHONE)
credit.card$FLAG_PHONE  = as.factor(credit.card$FLAG_PHONE)
credit.card$FLAG_EMAIL  = as.factor(credit.card$FLAG_EMAIL)
credit.card$ID = as.factor(credit.card$ID)

str(credit.card)

summary(credit.card)
```
Observations
* DAYS_EMPLOYED contains some positive values as well
* CNT_CHILDREN and CNT_FAM_MEMBERS variables have a very high maximum 
* OCCUPATION_TYPE variable has about 30% missing data 

#### Abnormality Check

As per the above observations abnormalities in the data was studied
```{r Abnormality Check}
# Why there are +ve values in Days_employed?!
credit.card[credit.card$DAYS_EMPLOYED >0,]  # 75,329 positive values
table(credit.card[credit.card$DAYS_EMPLOYED >0,]$NAME_INCOME_TYPE)
```
Observations 
All positive values corresponds to pensioners. Why? 
* All pensioners have days employed as 365243 (which is a default value); 75k such observations are there. After merging both the datasets if these values are still present some action will be taken

#### Conversion of "DAYS_BIRTH" and "DAYS_EMPLOYED" variables into years
```{r days to years}
credit.card$age= -1*(credit.card$DAYS_BIRTH/365) #check how to consider leap years as well

credit.card$years_employed= -1*(credit.card$DAYS_EMPLOYED/365) #check how to consider leap years as well

summary(credit.card$age)
summary(credit.card$years_employed)
summary(credit.card$DAYS_EMPLOYED) 

#dropping "DAYS_BIRTH" and "DAYS_EMPLOYED"
names(credit.card)
credit.card = credit.card[, -c(11,12)]
summary(credit.card)

#Check for minimum employed years
min(credit.card[credit.card$years_employed > -1000, ]$years_employed)

```
New variables age and years_employed were created. 


#### Checking for Duplicates
```{r}
check = as.data.frame(table(credit.card$ID))
dim(check)

check[check$Freq>=2,]

credit.card[credit.card$ID == 7036518,] #multiple values for the same client ##abnormal 

dim(credit.card)[1]-length(unique(credit.card$ID)) #not unique values

```
* Multiple records were observed under the same customer ID for 47 IDs.
* Such IDs can be treated as distinct because only the ID is same but the rest of the data is unique that can be used for modelling. Hence, these values were not dropped.

#### Outlier Analysis

```{r Boxplots}
par(mfrow=c(2,3))
boxplot(credit.card$AMT_INCOME_TOTAL, main= "AMT_INCOME_TOTAL", col="lightblue")
boxplot(credit.card$CNT_CHILDREN, main="CNT_CHILDREN", col= "lightgreen")
boxplot(credit.card$CNT_FAM_MEMBERS, main= "CNT_FAM_MEMBERS", col="orange")
boxplot(credit.card$age, main= "Age", col="cyan")
boxplot(credit.card$years_employed, main= "years_employed", col="purple")
```
* Outliers can be observed in AMT_INCOME_TOTAL, CNT_CHILDREN, CNT_FAM_MEMBERS, and years_employed

Outlier Count
```{r Outliers count}

length(boxplot(credit.card$CNT_CHILDREN, plot = F)$out)#about 6k , check targets in these 
length(boxplot(credit.card$AMT_INCOME_TOTAL, plot =F)$out)#check different percentiles after merging
length(boxplot(credit.card$CNT_FAM_MEMBERS, plot = F)$out)#about 5k , check overlap with cnt_children
length(boxplot(credit.card$years_employed, plot =F)$out)

```
Observed outliers will be taken care of after merging

#### Variable type modification in "credit record" data set
```{r Type modification 2}
credit.record$ID = as.character(credit.record$ID)
credit.record$MONTHS_BALANCE = as.factor(credit.record$MONTHS_BALANCE)

summary(credit.record)

table((credit.record$STATUS))
```

#### Understanding the credit record data set
```{r Understanding check}
as.data.frame(table(credit.record$ID))

credit.record[credit.record$ID == 5001718, ]
```
Multiple entries of ID are there as there is data for multiple months for a particular ID

#### Default(Bad score) categorization

As per banking industry standards of a risky customer (i.e. based on long overdues) and definition of Status variable, a record is marked as default if "Status" is 3,4, or 5 and delinquent if 1 or 2

```{r Bad Score categorization}
credit.record = as.data.frame(credit.record)
bad.score = subset(credit.record, credit.record$STATUS %in% c(3,4,5))
dim(bad.score)

length(unique(bad.score$ID))
length(unique(credit.record$ID))
```
331 deafault observations out of a total population of 45985 accounts/customers

#### Variables for Default and Delinquent

```{r Default and Deliquent variables}
credit.record['default'] = ifelse(credit.record$STATUS %in% c(3,4,5),1,0)
credit.record['delinq'] = ifelse(credit.record$STATUS == 2 ,1,0)
#did this to get a unique value for each client
agg_creditdata = credit.record %>% group_by(ID) %>% summarize(default=sum(default),delinq=sum(delinq))

dim(agg_creditdata)
head(agg_creditdata)
```
Since, a customer has records for different months, default flag is created by aggregating the data on customer level. If a customer was in default status atleast once it is marked as default

```{r Final Binary classification}
agg_creditdata['default'] = ifelse(agg_creditdata$default != 0,1,0)
agg_creditdata['delinq'] = ifelse(agg_creditdata$delinq != 0 ,1,0)

agg_creditdata$default = factor(agg_creditdata$default)
agg_creditdata$delinq = factor(agg_creditdata$delinq)

summary(agg_creditdata)
```
Observations:
* Number of Default observation  = 331 that is 0.7% of the total data
* Number of Delinquent observation = 597 that is 1.3% of the total data

#### Master Data (merging both the data sets by ID)

Both the data sets were merged on ID variable
```{r Merge}
final.data = merge(x= credit.card, y= agg_creditdata, by.x = "ID", by.y = "ID")

dim(final.data)
summary(final.data)
```
Observations:
* 36,457 observations are left
* Default and Delinquent are 0.8% and 1.5% respectively of the total data at hand
* Data is imbalanced as we have less number of default observations
* OCCUPATION_TYPE still has 31% missing values
* FLAG_MOBIL has only one value (i.e. 1), hence, it will be removed

Occupation is an important parameter to assess risk of default for a customer. Hence, despite of OCCUPATION_TYPE having too many NA values it will be retained and the NA observations will be removed as imputation is not an option here.

```{r Cleaning}
#assign NA's in occupation type
final.data = final.data %>% mutate_all(na_if,"")

#removed flag_mobil as it has single obs and ID too (reg mod not running because of it) and the missing values
final.data1 = subset(final.data, is.na(final.data$OCCUPATION_TYPE) == F, select = -c(1,11))

summary(final.data1[ ,c(17,18)]) #count
```
Observations
* Now, 25,134 observation left
* Default and Delinquent are 0.8% and 1.5% respectively of the total data at hand

#### EDA
```{r Histograms}
par(mfrow = c(2,3))
hist(final.data1$CNT_CHILDREN, col = "cyan", main = "CNT_CHILDREN")
hist(final.data1$CNT_FAM_MEMBERS, col = "cyan", main = "CNT_FAM_MEMBERS")
hist(final.data1$AMT_INCOME_TOTAL, col = "cyan", main = "AMT_INCOME_TOTAL")
hist(final.data1$age, col = "cyan", main = "Age")
hist(final.data1$years_employed, col = "cyan", main = "years_employed")
```
```{r}
par(mfrow = c(2,4))
barplot(table(final.data1$CODE_GENDER), col = "cyan", main = "CODE_GENDER")
barplot(table(final.data1$FLAG_OWN_CAR), col = "cyan", main = "FLAG_OWN_CAR")
barplot(table(final.data1$FLAG_OWN_REALTY), col = "cyan", main = "FLAG_OWN_REALTY")
barplot(table(final.data1$FLAG_WORK_PHONE), col = "cyan", main = "FLAG_WORK_PHONE")
barplot(table(final.data1$FLAG_PHONE), col = "cyan", main = "FLAG_PHONE")
barplot(table(final.data1$FLAG_EMAIL), col = "cyan", main = "FLAG_EMAIL")
barplot(table(final.data1$default), col = "cyan", main = "default")
barplot(table(final.data1$delinq), col = "cyan", main = "delinq")
```
```{r}
plot_bar(final.data1$OCCUPATION_TYPE, ggtheme = theme_test(), title = "OCCUPATION_TYPE")
plot_bar(final.data1$NAME_INCOME_TYPE, ggtheme = theme_test(), title = "NAME_INCOME_TYPE")
plot_bar(final.data1$NAME_EDUCATION_TYPE, ggtheme = theme_test(), title = "NAME_EDUCATION_TYPE")
plot_bar(final.data1$NAME_FAMILY_STATUS, ggtheme = theme_test(), title = "NAME_FAMILY_STATUS")
plot_bar(final.data1$NAME_HOUSING_TYPE, ggtheme = theme_test(), title = "NAME_HOUSING_TYPE")
```
Observations: 
* final dataset has more observations corresponding to:
  ** Female
  ** No Car
  ** Own a real state property
  ** No work phone
  ** No phone
  ** No email
  ** Ocupation - Laborers
  ** Income type - Working
  ** Education type - Secondary
  ** Family status - Married
  ** Housing type - House/apartment
  
#### Outlier Analysis - II
```{r}
length(boxplot(final.data1$CNT_CHILDREN, plot = F)$out) # about 6k , check targets in these 
length(boxplot(final.data1$AMT_INCOME_TOTAL, plot = F)$out) # check different percentiles after merging
length(boxplot(final.data1$CNT_FAM_MEMBERS, plot = F)$out) # about 5k , check overlap with cnt_children
length(boxplot(final.data1$years_employed, plot = F)$out) # outliers observed

table(boxplot(final.data1$CNT_CHILDREN, plot = F)$out) #some outliers observed 7,14,19

out_inc = boxplot(final.data1$AMT_INCOME_TOTAL, plot = F)$out

out_cnt = boxplot(final.data1$CNT_CHILDREN, plot = F)$out

out_fam = boxplot(final.data1$CNT_FAM_MEMBERS, plot = F)$out

out_yemp = boxplot(final.data1$years_employed, plot = F)$out

table(final.data1[which(final.data1$CNT_CHILDREN %in% out_cnt 
                        | final.data1$AMT_INCOME_TOTAL %in% out_inc
                        | final.data1$CNT_FAM_MEMBERS %in% out_fam),]$default)

```
* Cnt_children contains 5 default values out of 393
* amt_income_total contains 18 default values out of 11k
* Not removing outliers as the values doesn't seem to be unrealistic or wrong as per intuition


##---------Modelling----------##

(70-30) Train-Test Sampling 
```{r Sampling}
#sampling
set.seed(2205)
split = sample.split(final.data1$default, SplitRatio = 0.70)

card.train = subset(final.data1, split == TRUE)
card.test = subset(final.data1, split == FALSE)

#unique values
table(card.train$default)
table(card.test$default)
```
Observations:
* In the training sample there are very few defaulters to build model on, SMOTE will be used to treat this imbalance 

#### SMOTE
```{r SMOTE}
#study perc.over and under and limitations of smote like upto what extent we can create data
#created ~9% default values
card.train1 = SMOTE(default~., card.train, perc.over = 900, perc.under = 1150)

table(card.train$default)
table(card.train1$default)
```
SMOTE resulted in increased default percentage in train data from 0.8% to 8.8%

#### Full Logistic regression model 
```{r Full logistic model}
#model with all variables
log_mod = glm(default~., family = "binomial", card.train1)
summary(log_mod)
```

#### Variable Selection

Variable selection was performed using stepwise method on the basis of AIC and BIC both

```{r Stepwise AIC}
#Stepwise 
card_step = step(log_mod, direction = "both") #AIC

summary(card_step)
```

Residual Deviance from best AIC based model is 3351

```{r Stepwise BIC}
card_step_bic = step(log_mod, direction = "both", k = log(nrow(card.train1))) #BIC
summary(card_step_bic)
```

Residual deviance for BIC model is 3458.2

### Model Performance

#### In-sample and Out-of-sample performance 
```{r Train Test predictions}
#prediction on training data (stepwise AIC model)
pred_step_train_AIC = predict(card_step, type = "response")

#prediction on training data (stepwise BIC model)
pred_step_train_BIC = predict(card_step_bic, type = "response")

#prediction on test data (stepwise AIC model)
pred_step_AIC = predict(card_step, newdata = card.test, type = "response")

#prediction on test data (step BIC model)
pred_step_BIC = predict(card_step_bic, newdata = card.test, type = "response")
```

#### ROC Curves and Area Under Curve (AUC)

```{r ROC curves for AIC and BIC} 
#ROC curve (step AIC model)
pred1 = prediction(pred_step_AIC, card.test$default)
perf1 = performance(pred1, "tpr", "fpr")
plot(perf1, colorize=TRUE, main = "AIC Model")
unlist(slot(performance(pred1, "auc"), "y.values"))

#ROC curve (step BIC model)
pred = prediction(pred_step_BIC, card.test$default)
perf = performance(pred, "tpr", "fpr")
plot(perf, colorize=TRUE, main = "BIC Model")
unlist(slot(performance(pred, "auc"), "y.values"))
```

AUC for step BIC model is more as compared to AIC model. BIC selects less number of predictor variables and has residual deviance of 3374. Since there is not much difference in the deviance but BIC model is less complex. Hence, BIC model has been selected

#### Optimal cut off probability for confusion matrix

For selecting optimal pcut cost function was defined which assigns weight to false positives and false negatives. As false negatives are more crucial in card defaults, weight of 10 is assigned to these. 
For pcut values from 0.01 to 1 cost was calculated. pcut corresponding to minimum cost is optimal pcut.
```{r optimal pcut}
#considering asymmetric cost
costfunc = function(obs, pred.p, pcut){
    weight1 = 10   # weight for "true=1 but pred=0" (FN)
    weight0 = 1    # weight for "true=0 but pred=1" (FP)
    c1 = (obs==1)&(pred.p<pcut)    # count for "true=1 but pred=0"   (FN)
    c0 = (obs==0)&(pred.p>=pcut)   # count for "true=0 but pred=1"   (FP)
    cost = mean(weight1*c1 + weight0*c0)  # misclassification with weight
    return(cost) 
}

# sequence from 0.01 to 1 by 0.01
p.seq = seq(0.01, 1, 0.01) 

# loop for all p-cut to see which one provides the smallest cost
cost1 = rep(0, length(p.seq))  
for(i in 1:length(p.seq)){ 
    cost1[i] = costfunc(obs = card.train1$default, pred.p = pred_step_train_BIC, pcut = p.seq[i])  
} 
plot(p.seq, cost1)

p.seq[which(cost1==min(cost1))] #optimal cut off prob

```
Optimal p_cut came out to be 0.09.

#### Confusion matrix
```{r confusion matrix BIC}
#binary classification
pred_step_BIC_b = (pred_step_BIC>0.11)*1

#confusion matrix
table(card.test$default, pred_step_BIC_b, dnn = c("True", "Predicted"))

#misclassification rate
MR1 = mean(card.test$default != pred_step_BIC_b)
MR1
```

Since False negatives are of more concern here, recall is calculated for model assessment

Cross Validation on models
```{r Cross Validation}

costfunc1 = function(obs, pred.p){
    weight1 = 10   # weight for "true=1 but pred=0" (FN)
    weight0 = 1    # weight for "true=0 but pred=1" (FP)
    c1 = (obs==1)&(pred.p<0.11)    # count for "true=1 but pred=0"   (FN)
    c0 = (obs==0)&(pred.p>=0.11)   # count for "true=0 but pred=1"   (FP)
    cost = mean(weight1*c1 + weight0*c0)  # misclassification with weight
    return(cost) 
}

#AIC model

#check 
check.mod = glm(default~., family = "binomial", data = final.data1)

#summary(check.mod)

cv.result.bic = cv.glm(data=final.data1, glmfit = card_step_bic, cost=costfunc1, K=5) 
cv.result.bic$delta[2]
```

Classification tree
```{r CART}
card.tree = rpart(formula = default ~ . , data = card.train1, method = "class", 
                  parms = list(loss=matrix(c(0,10,1,0))))
card.tree

prp(card.tree, extra = 1)

#nrow check: getting exact same tree without the nrow argument
```
*From BIC as well we observed that age and years_employed are not included for classification 


prediction from classification tree model
```{r prediction CART}
pred.card.tree = predict(card.tree, card.test, type="class")
table(card.test$default, pred.card.tree, dnn=c("Truth","Predicted"))

MR2 = mean(card.test$default != pred.card.tree)
MR2

#ROC curve
pred.card.tree.prob = predict(card.tree, card.test, type="prob")

pred2 = prediction(pred.card.tree.prob[,2], card.test$default)
perf2 = performance(pred2, "tpr", "fpr")
plot(perf2, colorize=TRUE)

slot(performance(pred2, "auc"), "y.values")[[1]] #AUC

```

chi sq test 
Drop this analysis ?????????
```{r ChiSQ}
names(final.data1)


as.data.frame(lapply(final.data1[,-17], function(x) chisq.test(table(x,final.data1$default), simulate.p.value = TRUE)$p.value))

chisq.test(final.data1$default, final.data1$NAME_EDUCATION_TYPE)
```

Random Forest
```{r RF}
library(randomForest)
card.rf = randomForest(default~., data = card.train1, ntree = 1000) # 500 trees is fine too
card.rf
```
```{r ntrees vs fnr}
plot(card.rf, lwd=rep(2, 3))
legend("top", legend = c("OOB Error", "FPR", "FNR"), lwd=rep(2, 3), lty = c(1,2,3), col = c("black", "red", "green"))
```
The above plots tells that FNR is decreasing with increase in the number of trees

optimal cut off prob
```{r optimal pcut RF}
card.rf.pred = predict(card.rf, type = "prob")[,2]

cost.rf = rep(0, length(p.seq))  
for(i in 1:length(p.seq)){ 
    cost.rf[i] = costfunc(obs = card.train1$default, pred.p = card.rf.pred, pcut = p.seq[i])  
}
plot(p.seq, cost.rf)

optimal.pcut.rf= p.seq[which(cost.rf==min(cost.rf))] #0.08   
```

confusion matrix
```{r}
card.rf.pred.test = predict(card.rf, newdata=card.test, type = "prob")[,2]
card.rf.class.test = (card.rf.pred.test>optimal.pcut.rf)*1
table(card.test$default, card.rf.class.test, dnn = c("True", "Pred"))

mr.rf = mean(card.test$default != card.rf.class.test)
mr.rf
```

